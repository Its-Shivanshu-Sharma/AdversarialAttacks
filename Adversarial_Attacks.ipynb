{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWSD0alBuvpp"
   },
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"https://colab.research.google.com/github/Its-Shivanshu-Sharma/AdversarialAttacks/blob/main/Adversarial_Attacks.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "    </a>\n",
    "</div>\n",
    "    \n",
    "<div align=\"right\">\n",
    "    <a href=\"https://console.paperspace.com/github/Its-Shivanshu-Sharma/AdversarialAttacks/blob/main/Adversarial_Attacks.ipynb\">\n",
    "        <img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LZcCeo9X7xi"
   },
   "source": [
    "# Adversarial Attacks on Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNav9CYmZsdd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QVHLif75cnA"
   },
   "source": [
    "## Table of Contents:\n",
    "- ### [Installing & Importing packages, libraries, etc](#installing-&-importing-packages,-libraries,-etc)\n",
    "- ### [Fetching & preparing the Dataset](#fetching-&-preparing-the-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFWEuQ3u5z0N"
   },
   "source": [
    "<a name=\"installing-&-importing-packages,-libraries,-etc\"></a>\n",
    "\n",
    "---\n",
    "## Installing & Importing packages, libraries, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HJsyfALrBTW"
   },
   "source": [
    "### Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G8s1KNcJfoxa"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip3 install -qq torch==1.10.2+cu113 torchvision==0.11.3+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDk7qQDqrIeU"
   },
   "source": [
    "### Importing packages, libraries, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "el8Fq5oY_msX"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mousomyU34n",
    "outputId": "92337284-81cf-4660-d4e9-49648350b682"
   },
   "outputs": [],
   "source": [
    "# Setting setting the seed for the RNG (Random Number Generator)\n",
    "# for reproducibility\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lvRdns8gdVv"
   },
   "source": [
    "<a name=\"fetching-&-preparing-the-dataset\"></a>\n",
    "\n",
    "---\n",
    "## Fetching & preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aT679M1uhTc1"
   },
   "source": [
    "We'll creating a model for binary classification using the [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RvLbTA7qaEJY",
    "outputId": "d9cc7d44-6fcc-4577-a7ba-d661d2cd49cc"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create a new directory to store the dataset\n",
    "mkdir pets_dataset\n",
    "cd pets_dataset\n",
    "wget -q https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "wget -q https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
    "tar -xf images.tar.gz\n",
    "tar -xf annotations.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sVb6sNNRrf9y"
   },
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRfB75Hhri2y"
   },
   "outputs": [],
   "source": [
    "path = Path(\"/content/pets_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RBTVHo7rklM"
   },
   "outputs": [],
   "source": [
    "def ls(path):\n",
    "    for f in path.iterdir():\n",
    "        print(f\"{'d' if f.is_dir() else 'f': <4}{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9yz7XEHiv25",
    "outputId": "8ff40b61-94e9-454f-a93a-9e3f7dc13f63"
   },
   "outputs": [],
   "source": [
    "ls(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XiVcfGmj8Gwl"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QDYG1qLAlLZm",
    "outputId": "63d65543-2bc0-47a7-ce95-5406c10fe641"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    path / \"annotations\" / \"list.txt\",\n",
    "    skiprows=6,\n",
    "    header=None,\n",
    "    names=[\"file_name\", \"class_id\", \"species\", \"breed_id\"],\n",
    "    sep=\" \",\n",
    ")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_Uuk1NSInaEf",
    "outputId": "da3fa37b-263b-47dd-82e5-5c27b66be16f"
   },
   "outputs": [],
   "source": [
    "df = df.loc[:, [\"file_name\", \"species\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI-dKqW41pvA"
   },
   "source": [
    "#### Change the labels (i.e. `species`) such that:\n",
    "`Cat = 0` & `Dog = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IRHEaiIaqQ7k"
   },
   "outputs": [],
   "source": [
    "new_label_map = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jpkjuix4uvqb"
   },
   "outputs": [],
   "source": [
    "df.loc[:, \"species\"] = df.loc[:, \"species\"].apply(new_label_map.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xD_Sw4xhqroM",
    "outputId": "718b1ca5-0a21-49f2-ad1b-1e09ea9fea25"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NtKR3StCrWg9"
   },
   "outputs": [],
   "source": [
    "def train_val_split(data, train_sz=None, val_sz=None):\n",
    "    \"\"\"Function to randomly split data into training & validation sets\n",
    "    Parameters:\n",
    "        data (pandas.DataFrame) - dataframe containing the annotations for the\n",
    "                                    images\n",
    "        train_sz (float) - fraction of data to be allocated to training set\n",
    "        val_sz (float) - fraction of data to be allocated to test set\n",
    "                            (`test_sz` is ignored if `train_sz` is not `None`)\n",
    "\n",
    "    Returns:\n",
    "        A tuple containing Dataframes for the training and validation sets,\n",
    "        i.e. returns `(train_set, val_set)`.\n",
    "    \"\"\"\n",
    "    size = len(data)\n",
    "    # Calculate length of the training set\n",
    "    if train_sz:\n",
    "        train_len = int(train_sz * size)\n",
    "    elif val_sz:\n",
    "        train_len = size - int(val_sz * size)\n",
    "\n",
    "    # Randomly generate training and validation datasets\n",
    "    idxs = torch.randperm(size)\n",
    "    train_set = data.iloc[idxs[:train_len], :].reset_index(drop=True)\n",
    "    val_set = data.iloc[idxs[train_len:], :].reset_index(drop=True)\n",
    "\n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uoG4aGM0tWaZ"
   },
   "outputs": [],
   "source": [
    "train_set, val_set = train_val_split(df, train_sz=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Vj-EpFN9NZvq",
    "outputId": "9f410aff-c4ff-4b19-e9a4-96aabfc2d26a"
   },
   "outputs": [],
   "source": [
    "train_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxafAuo7Jton"
   },
   "source": [
    "#### Create `Dataset` objects for the training & validations sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1fP9PQOL7neO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import Resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-th5bwHuqfCL"
   },
   "outputs": [],
   "source": [
    "class PetsDataset(Dataset):\n",
    "    \"\"\"Custom defined Dataset subclass for working with the IIIT-Pets Dataset\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations,\n",
    "        img_dir,\n",
    "        img_format=\"jpg\",\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "    ):\n",
    "        \"\"\"Parameters:\n",
    "        annotations (pandas.DataFrame) - dataframe containing the annotations\n",
    "        img_dir (str or Path object) - path to directory containing images\n",
    "        img_format (str: default = 'jpg') - format of the images\n",
    "        transform (callable; optional) - Tranformation to apply to images\n",
    "        target_transform (callable; optional) - Transformation to apply to\n",
    "                                                target labels\n",
    "        \"\"\"\n",
    "        self.annotations = annotations\n",
    "        self.img_dir = img_dir\n",
    "        self.img_format = img_format\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.annotations.iloc[index, 0] + \".\" + self.img_format\n",
    "        img_file = os.path.join(self.img_dir, file_name)\n",
    "        image = read_image(img_file)\n",
    "        label = self.annotations.iloc[index, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yczbO1JwMQWS"
   },
   "source": [
    "### **Note:** Some images have an additional `alpha` channel for transparency.<br>This will cause problems, hence, we will simply remove this additional channel using the `resize_remove` tranform on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s6wMlTQrIxiw"
   },
   "outputs": [],
   "source": [
    "def resize_remove(img_size):\n",
    "    \"\"\"This function will resize the image to the passed size using `torchvision.transforms.Resize`\n",
    "    and will keep only the first `img_size[0]` number of channels.\n",
    "\n",
    "    Parameters:\n",
    "        img_size (tuple or array-like) - specifies the size\n",
    "                                        (channels, height, width) to which the\n",
    "                                        image must be resized\n",
    "    Returns:\n",
    "        a callable that will resize the image & remove extra channels\n",
    "    \"\"\"\n",
    "    resizer = Resize(img_size[1:])\n",
    "\n",
    "    def transform(img):\n",
    "        return resizer(img[: img_size[0], :, :])\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64O4eKQXLqEr"
   },
   "outputs": [],
   "source": [
    "# Define the image size in (C, H, W) format\n",
    "img_size = (3, 150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USqNFV8v3HFM"
   },
   "outputs": [],
   "source": [
    "train_data = PetsDataset(\n",
    "    train_set, img_dir=path / \"images\", transform=resize_remove(img_size)\n",
    ")\n",
    "val_data = PetsDataset(\n",
    "    val_set, img_dir=path / \"images\", transform=resize_remove(img_size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEktVXxNOEc2"
   },
   "source": [
    "### Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nwk70HlX8JnF"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuuwdKUwYKwo"
   },
   "outputs": [],
   "source": [
    "def viz_data(data, label_map, n_rows=3, n_cols=3):\n",
    "    \"\"\"Function to display n_rows*n_cols number of images of the Dataset\n",
    "    Parameters:\n",
    "        data (Dataset or its subclass) - data which has to be visualized\n",
    "        label_map (dict) - mapping from int to labels for the classes\n",
    "        n_rows (int) - no. of rows of images to display\n",
    "        n_cols (int) - no. of columns of images to display\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    # Randomly choose the images to display from the data\n",
    "    idxs = torch.randint(high=len(data), size=(n_rows * n_cols,)).tolist()\n",
    "\n",
    "    for i, idx in enumerate(idxs):\n",
    "        img, label = data[idx]\n",
    "        figure.add_subplot(n_rows, n_cols, i + 1)\n",
    "        plt.title(label_map.get(label))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img.permute((1, 2, 0)))  # change image to (H,W,C) format\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayS1PSQid4eo"
   },
   "outputs": [],
   "source": [
    "species_map = {\n",
    "    0: \"Cat\",\n",
    "    1: \"Dog\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 482
    },
    "id": "pKEpG7ceZMzF",
    "outputId": "8b6f7369-f993-429d-caa8-61cc2a22c5db"
   },
   "outputs": [],
   "source": [
    "viz_data(train_data, species_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUDHSNpmJ1GE"
   },
   "source": [
    "#### Create `DataLoader` objects for the training & validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZItRO-B27FwJ"
   },
   "outputs": [],
   "source": [
    "# define the batch size\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMzcEGxv7lF4"
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=bs, shuffle=True)\n",
    "val_dataloader = DataLoader(val_data, batch_size=bs, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLcvbTwl9dKn"
   },
   "source": [
    "<a name=\"training-a-deep-neural-network-for-binary-classification\"></a>\n",
    "\n",
    "---\n",
    "## Training a Deep Neural Network for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBLf7veO_yZ5"
   },
   "source": [
    "In this section we will be training a simple `Feed-Forward Neural Network` on our pets dataset.<br> The output of the network will be one of the 2 classes, i.e. `Cat` or `Dog`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAsbbr5Suvqr"
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "from torch.optim.sgd import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKtWmjCu944P"
   },
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    \"\"\"A class defining a simple Feedforward neural network\"\"\"\n",
    "\n",
    "    def __init__(self, img_size):\n",
    "        \"\"\"Parameters:\n",
    "        img_size - dimensions of the input image\n",
    "        \"\"\"\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        input_size = reduce(lambda x, y: x * y, img_size)\n",
    "\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J2ZX_XNm_6_B"
   },
   "outputs": [],
   "source": [
    "def train_loop(train_dataloader, model, loss_fn, optimizer, device=\"cpu\"):\n",
    "    \"\"\"Function to perform the training on the data for one epoch.\n",
    "\n",
    "    Parameters:\n",
    "    train_dataloader (DataLoader) - dataloader object for the training data\n",
    "    model - the model which has to be trained (& used for making predictions)\n",
    "    loss_fn (function) - loss function to use for calculating the gradients\n",
    "    optimizer - optimizer to use for updating the parameters of the model\n",
    "    device (str: default=\"cpu\") - device to use for training the model\n",
    "\n",
    "    Returns: (float)\n",
    "    Average of training loss taken across all the batches\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for x, y in train_dataloader:\n",
    "        x = x.float().to(device)\n",
    "        y = y.float().unsqueeze(1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(x)\n",
    "        # Calculate loss & gradients\n",
    "        loss = loss_fn(pred, y)\n",
    "        avg_loss += loss.item()\n",
    "        loss.backward()\n",
    "        # Update parameter values\n",
    "        optimizer.step()\n",
    "    return avg_loss / len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s_iGTBa1Bix3"
   },
   "outputs": [],
   "source": [
    "def val_loop(val_dataloader, model, loss_fn, threshold=0.5, device=\"cpu\"):\n",
    "    \"\"\"Function to calculate the loss & accuracy of the model for the validation\n",
    "    dataset.\n",
    "\n",
    "    Parameters:\n",
    "    val_dataloader (DataLoader) - dataloader object for the validation data\n",
    "    model - model for making the predictions\n",
    "    loss_fn (function) - loss function to use for calculating the gradients\n",
    "    threshold (float: default=0.5) - threshold value above which the prediction\n",
    "                                    will be classified as belonging to class `1`\n",
    "    device (str: default=\"cpu\") - device to use for inference\n",
    "\n",
    "    Returns: (tuple)\n",
    "    Average of validation loss (taken across all the batches) & accuracy of the\n",
    "    model,\n",
    "    i.e. tuple of format (average loss, accuracy)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    avg_loss = 0\n",
    "    correct = 0\n",
    "    # Gradient need not be computed for the validation data, hence, computations\n",
    "    # can be sped up\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_dataloader:\n",
    "            x = x.float().to(device)\n",
    "            y = y.float().unsqueeze(1).to(device)\n",
    "            pred = model(x)\n",
    "            avg_loss += loss_fn(pred, y).item()\n",
    "            correct += ((pred > threshold) == y).float().sum().item()\n",
    "    return avg_loss / len(val_dataloader), correct / len(val_dataloader.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebSHpLTZuvqu"
   },
   "source": [
    "### Create, train & validate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0sEIybwtQre"
   },
   "source": [
    "##### Use `GPU` for training if available else use `CPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3cwG_3Iztq58",
    "outputId": "6b5be83a-1e2c-4396-d42f-b0acba5307bd"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device being used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEv13zkFt7OB"
   },
   "outputs": [],
   "source": [
    "model = FeedForwardNetwork(img_size)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12Yinrb_OrWJ"
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "lr = 1e-3\n",
    "optimizer = SGD(model.parameters(), lr)\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kewGb2JbsOvr",
    "outputId": "47746c55-87a4-4873-85e8-678cbeb1da77",
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    [],\n",
    "    columns=[\"Training Loss\", \"Validation Loss\", \"Accuracy\"],\n",
    "    index=pd.Index([], name=\"Epoch No.\"),\n",
    ")\n",
    "for i in range(n_epochs):\n",
    "    train_loss = train_loop(train_dataloader, model, bce_loss, optimizer, device=device)\n",
    "    val_loss, accuracy = val_loop(val_dataloader, model, bce_loss, device=device)\n",
    "    results.loc[i] = [train_loss, val_loss, accuracy]\n",
    "    print(results.loc[i].to_frame().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 551
    },
    "id": "Qn4AYQ-VZb11",
    "outputId": "e6762ac3-a8a4-4f4e-c501-bae53b980fb8"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GtTSoRlxKYb"
   },
   "source": [
    "### Creating an Adversarial Example for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pdr6QGEU1Ek3"
   },
   "outputs": [],
   "source": [
    "x, y = val_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "WfVnUw8-4Mne",
    "outputId": "5b1989fc-59e4-433f-cfba-e437c3ce11d3"
   },
   "outputs": [],
   "source": [
    "species_map.get(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IflxqhGU10IB"
   },
   "outputs": [],
   "source": [
    "x_new = x.detach().clone().float().unsqueeze(0).to(device).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPJSIFeI2CtI"
   },
   "outputs": [],
   "source": [
    "y_new = 0 if y == 1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7DIH57cMNZN"
   },
   "outputs": [],
   "source": [
    "y_new = torch.Tensor([[y_new]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "Sj4mrx4H4_Sc",
    "outputId": "45a4bd56-c031-4250-e949-0c43a1685d0e"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x_new.permute((1, 2, 0)).type(torch.uint8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(species_map.get(y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zWsOiwg33OQ"
   },
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "lr = 1e-1\n",
    "momentum = 0.9\n",
    "loss_func = nn.BCELoss()\n",
    "opt = SGD([x_new], lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "StnnLD8p8lXn",
    "outputId": "cf27e5c4-5e36-42d5-bd4d-d79b5076c3fc"
   },
   "outputs": [],
   "source": [
    "model(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hc-760tDL53Q"
   },
   "outputs": [],
   "source": [
    "for i in range(n_epochs):\n",
    "    pred = model(x_new)\n",
    "    opt.zero_grad()\n",
    "    loss = loss_func(pred, y_new)\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "emwTyD14EXj0",
    "outputId": "66fab4c4-07e9-43d1-e495-7d552c960fa7"
   },
   "outputs": [],
   "source": [
    "model(x_new)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "5QVHLif75cnA"
   ],
   "name": "Adversarial_Attacks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
