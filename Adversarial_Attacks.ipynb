{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LWSD0alBuvpp"
   },
   "source": [
    "<div align=\"right\">\n",
    "    <a href=\"https://colab.research.google.com/github/Its-Shivanshu-Sharma/AdversarialAttacks/blob/main/Adversarial_Attacks.ipynb\">\n",
    "        <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
    "    </a>\n",
    "</div>\n",
    "    \n",
    "<div align=\"right\">\n",
    "    <a href=\"https://console.paperspace.com/github/Its-Shivanshu-Sharma/AdversarialAttacks/blob/main/Adversarial_Attacks.ipynb\">\n",
    "        <img src=\"https://assets.paperspace.io/img/gradient-badge.svg\" alt=\"Run on Gradient\"/>\n",
    "    </a>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4LZcCeo9X7xi"
   },
   "source": [
    "# Adversarial Attacks on Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZNav9CYmZsdd"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5QVHLif75cnA"
   },
   "source": [
    "## Table of Contents:\n",
    "- ### [Installing & Importing packages, libraries, etc](#installing-&-importing-packages,-libraries,-etc)\n",
    "- ### [Fetching & preparing the Dataset](#fetching-&-preparing-the-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SFWEuQ3u5z0N"
   },
   "source": [
    "<a name=\"installing-&-importing-packages,-libraries,-etc\"></a>\n",
    "\n",
    "---\n",
    "## Installing & Importing packages, libraries, etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5HJsyfALrBTW"
   },
   "source": [
    "### Installing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8s1KNcJfoxa",
    "outputId": "026dadee-b2c2-4e7a-9cd3-83e7912d1707"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tcmalloc: large alloc 1147494400 bytes == 0x55efd7854000 @  0x7f296c9dc615 0x55ef9df9117c 0x55ef9e07147a 0x55ef9df93f9d 0x55ef9e085d4d 0x55ef9e007ec8 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e007d30 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e086b76 0x55ef9e003d95 0x55ef9e086b76 0x55ef9e003d95 0x55ef9e086b76 0x55ef9e003d95 0x55ef9df95ce9 0x55ef9dfd9579 0x55ef9df94902 0x55ef9e007c4d 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e0038f6 0x55ef9df957aa 0x55ef9e003b4f 0x55ef9e002a2e\n",
      "tcmalloc: large alloc 1434370048 bytes == 0x55f01beaa000 @  0x7f296c9dc615 0x55ef9df9117c 0x55ef9e07147a 0x55ef9df93f9d 0x55ef9e085d4d 0x55ef9e007ec8 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e007d30 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e086b76 0x55ef9e003d95 0x55ef9e086b76 0x55ef9e003d95 0x55ef9e086b76 0x55ef9e003d95 0x55ef9df95ce9 0x55ef9dfd9579 0x55ef9df94902 0x55ef9e007c4d 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e0038f6 0x55ef9df957aa 0x55ef9e003b4f 0x55ef9e002a2e\n",
      "tcmalloc: large alloc 1792966656 bytes == 0x55efa0cdc000 @  0x7f296c9dc615 0x55ef9df9117c 0x55ef9e07147a 0x55ef9df93f9d 0x55ef9e085d4d 0x55ef9e007ec8 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e007d30 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e086b76 0x55ef9e003d95 0x55ef9e086b76 0x55ef9e003d95 0x55ef9e086b76 0x55ef9e003d95 0x55ef9df95ce9 0x55ef9dfd9579 0x55ef9df94902 0x55ef9e007c4d 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e0038f6 0x55ef9df957aa 0x55ef9e003b4f 0x55ef9e002a2e\n",
      "tcmalloc: large alloc 2241208320 bytes == 0x55f00bac4000 @  0x7f296c9dc615 0x55ef9df9117c 0x55ef9e07147a 0x55ef9df93f9d 0x55ef9e085d4d 0x55ef9e007ec8 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e007d30 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e086b76 0x55ef9e003d95 0x55ef9e086b76 0x55ef9e003d95 0x55ef9e086b76 0x55ef9e003d95 0x55ef9df95ce9 0x55ef9dfd9579 0x55ef9df94902 0x55ef9e007c4d 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e0038f6 0x55ef9df957aa 0x55ef9e003b4f 0x55ef9e002a2e\n",
      "tcmalloc: large alloc 1821433856 bytes == 0x55f091426000 @  0x7f296c9db1e7 0x55ef9dfc7407 0x55ef9df9117c 0x55ef9e07147a 0x55ef9df93f9d 0x55ef9e085d4d 0x55ef9e007ec8 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9df957aa 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e002a2e\n",
      "tcmalloc: large alloc 2276794368 bytes == 0x55f0fdd34000 @  0x7f296c9dc615 0x55ef9df9117c 0x55ef9e07147a 0x55ef9df93f9d 0x55ef9e085d4d 0x55ef9e007ec8 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e003b4f 0x55ef9df957aa 0x55ef9e003b4f 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e002a2e 0x55ef9df9588a 0x55ef9e004719 0x55ef9e002a2e 0x55ef9df95f21\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.10.2+cu113 which is incompatible.\n",
      "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.10.2+cu113 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 install -qq torch==1.10.2+cu113 torchvision==0.11.3+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDk7qQDqrIeU"
   },
   "source": [
    "### Importing packages, libraries, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "el8Fq5oY_msX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3mousomyU34n",
    "outputId": "5c3c68a8-6fcd-4de5-9dcb-d13022ce039c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f5995f3fcf0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting setting the seed for the RNG (Random Number Generator)\n",
    "# for reproducibility\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lvRdns8gdVv"
   },
   "source": [
    "<a name=\"fetching-&-preparing-the-dataset\"></a>\n",
    "\n",
    "---\n",
    "## Fetching & preparing the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aT679M1uhTc1"
   },
   "source": [
    "We'll creating a model for binary classification using the [Oxford-IIIT Pet Dataset](https://www.robots.ox.ac.uk/~vgg/data/pets/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "RvLbTA7qaEJY"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Create a new directory to store the dataset\n",
    "mkdir pets_dataset\n",
    "cd pets_dataset\n",
    "wget -q https://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz\n",
    "wget -q https://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz\n",
    "tar -xf images.tar.gz\n",
    "tar -xf annotations.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "IRfB75Hhri2y"
   },
   "outputs": [],
   "source": [
    "dataset_dir = Path(\"./pets_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "8RBTVHo7rklM"
   },
   "outputs": [],
   "source": [
    "def ls(path):\n",
    "    for f in path.iterdir():\n",
    "        print(f\"{'d' if f.is_dir() else 'f': <4}{f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9yz7XEHiv25",
    "outputId": "125cc0fd-ba7b-45cc-d0be-fb215de7acf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f   /content/pets_dataset/annotations.tar.gz\n",
      "d   /content/pets_dataset/images\n",
      "d   /content/pets_dataset/annotations\n",
      "f   /content/pets_dataset/images.tar.gz\n"
     ]
    }
   ],
   "source": [
    "ls(dataset_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "QDYG1qLAlLZm",
    "outputId": "5c1d9f20-b815-47d6-deaa-9bfd694acb42"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-a6af23ab-e4dd-49e3-acdd-7f180bc32c92\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>class_id</th>\n",
       "      <th>species</th>\n",
       "      <th>breed_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abyssinian_100</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abyssinian_101</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abyssinian_102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abyssinian_103</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abyssinian_104</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6af23ab-e4dd-49e3-acdd-7f180bc32c92')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a6af23ab-e4dd-49e3-acdd-7f180bc32c92 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a6af23ab-e4dd-49e3-acdd-7f180bc32c92');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        file_name  class_id  species  breed_id\n",
       "0  Abyssinian_100         1        1         1\n",
       "1  Abyssinian_101         1        1         1\n",
       "2  Abyssinian_102         1        1         1\n",
       "3  Abyssinian_103         1        1         1\n",
       "4  Abyssinian_104         1        1         1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = pd.read_csv(\n",
    "    dataset_dir / \"annotations\" / \"list.txt\",\n",
    "    skiprows=6,\n",
    "    header=None,\n",
    "    names=[\"file_name\", \"class_id\", \"species\", \"breed_id\"],\n",
    "    sep=\" \",\n",
    ")\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "_Uuk1NSInaEf",
    "outputId": "2355bb15-b931-4ec4-9222-c687c936784b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-e023c2cf-2763-429b-86f1-fd0e2a12e640\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abyssinian_100</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abyssinian_101</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abyssinian_102</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abyssinian_103</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abyssinian_104</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e023c2cf-2763-429b-86f1-fd0e2a12e640')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-e023c2cf-2763-429b-86f1-fd0e2a12e640 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-e023c2cf-2763-429b-86f1-fd0e2a12e640');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        file_name  species\n",
       "0  Abyssinian_100        1\n",
       "1  Abyssinian_101        1\n",
       "2  Abyssinian_102        1\n",
       "3  Abyssinian_103        1\n",
       "4  Abyssinian_104        1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = full_data.loc[:, [\"file_name\", \"species\"]]\n",
    "full_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PI-dKqW41pvA"
   },
   "source": [
    "#### Change the labels (i.e. `species`) such that:\n",
    "`Cat = 0` & `Dog = 1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "IRHEaiIaqQ7k"
   },
   "outputs": [],
   "source": [
    "new_label_map = {\n",
    "    1: 0,\n",
    "    2: 1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jpkjuix4uvqb"
   },
   "outputs": [],
   "source": [
    "full_data.loc[:, \"species\"] = full_data.loc[:, \"species\"].apply(new_label_map.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "xD_Sw4xhqroM",
    "outputId": "be71a2f6-0f19-447a-8226-bcff49de4f7b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-1a5d21ea-0251-4f1c-b023-99d7cc3d7bcb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abyssinian_100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Abyssinian_101</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abyssinian_102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Abyssinian_103</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Abyssinian_104</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a5d21ea-0251-4f1c-b023-99d7cc3d7bcb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-1a5d21ea-0251-4f1c-b023-99d7cc3d7bcb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-1a5d21ea-0251-4f1c-b023-99d7cc3d7bcb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "        file_name  species\n",
       "0  Abyssinian_100        0\n",
       "1  Abyssinian_101        0\n",
       "2  Abyssinian_102        0\n",
       "3  Abyssinian_103        0\n",
       "4  Abyssinian_104        0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "NtKR3StCrWg9"
   },
   "outputs": [],
   "source": [
    "def train_val_split(data, train_size=None, val_size=None):\n",
    "    \"\"\"Function to randomly split data into training & validation sets\n",
    "    Parameters:\n",
    "    -----------\n",
    "     - data (pandas.DataFrame): Dataframe containing the annotations for the images.\n",
    "    - train_size (float) - Fraction of data to be allocated to training set.\n",
    "    - val_size (float) - Fraction of data to be allocated to test set.\n",
    "                         (`val_size` is ignored if `train_size` is not None)\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    A tuple containing Dataframes for the training and validation sets,\n",
    "    i.e. returns `(train_set, val_set)`.\n",
    "    \"\"\"\n",
    "    size = len(data)\n",
    "    # Calculate length of the training set\n",
    "    if train_size:\n",
    "        train_len = int(train_size * size)\n",
    "    elif val_size:\n",
    "        train_len = size - int(val_size * size)\n",
    "\n",
    "    # Randomly generate training and validation datasets\n",
    "    idxs = torch.randperm(size)\n",
    "    train_set = data.iloc[idxs[:train_len], :].reset_index(drop=True)\n",
    "    val_set = data.iloc[idxs[train_len:], :].reset_index(drop=True)\n",
    "\n",
    "    return train_set, val_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "uoG4aGM0tWaZ"
   },
   "outputs": [],
   "source": [
    "data = {}\n",
    "data[\"train\"], data[\"val\"] = train_val_split(full_data, train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Vj-EpFN9NZvq",
    "outputId": "19520cb3-17e1-450e-a31d-e0906df23eec"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-712943d5-c16c-4cb2-9db8-ffe787364258\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>staffordshire_bull_terrier_174</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>beagle_73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abyssinian_192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>american_pit_bull_terrier_93</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>american_pit_bull_terrier_119</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-712943d5-c16c-4cb2-9db8-ffe787364258')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-712943d5-c16c-4cb2-9db8-ffe787364258 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-712943d5-c16c-4cb2-9db8-ffe787364258');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "                        file_name  species\n",
       "0  staffordshire_bull_terrier_174        1\n",
       "1                       beagle_73        1\n",
       "2                  Abyssinian_192        0\n",
       "3    american_pit_bull_terrier_93        1\n",
       "4   american_pit_bull_terrier_119        1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"train\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxafAuo7Jton"
   },
   "source": [
    "#### Create `Dataset` objects for the training & validations sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "-th5bwHuqfCL"
   },
   "outputs": [],
   "source": [
    "class PetsDataset(Dataset):\n",
    "    \"\"\"Custom defined Dataset subclass for working with the IIIT-Pets Dataset\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        annotations,\n",
    "        img_dir,\n",
    "        img_format=\"jpg\",\n",
    "        transform=None,\n",
    "        target_transform=None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - annotations (pandas.DataFrame) - Dataframe containing the annotations.\n",
    "        - img_dir (str or Path object) - Path to the directory containing images.\n",
    "        - img_format (str: default = 'jpg') - Format of the images.\n",
    "        - transform (callable; default=None) - Tranformation to apply to images.\n",
    "        - target_transform (callable; default=None) - Transformation to apply to\n",
    "                                                      target labels.\n",
    "        \"\"\"\n",
    "        self.annotations = annotations\n",
    "        self.img_dir = img_dir\n",
    "        self.img_format = img_format\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        file_name = self.annotations.iloc[index, 0] + \".\" + self.img_format\n",
    "        img_file = os.path.join(self.img_dir, file_name)\n",
    "        image = torchvision.io.read_image(img_file)\n",
    "        label = self.annotations.iloc[index, 1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yczbO1JwMQWS"
   },
   "source": [
    "### **Note:** Some images have an additional `alpha` channel for transparency.<br>This will cause problems, hence, we will simply remove this additional channel using the `resize_remove` tranform on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "s6wMlTQrIxiw"
   },
   "outputs": [],
   "source": [
    "def resize_remove(img_size):\n",
    "    \"\"\"This function will resize the image to the passed size using\n",
    "    `torchvision.transforms.functional.resize` and will keep only the\n",
    "    first `img_size[0]` number of channels.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - img_size (tuple or array-like) - specifies the size (channels, height, width)\n",
    "                                       to which the image must be resized.\n",
    "    Returns:\n",
    "    --------\n",
    "    A callable that will resize the image & remove extra channels.\n",
    "    \"\"\"\n",
    "    num_channels = img_size[0]\n",
    "\n",
    "    def transform(img):\n",
    "        return TF.resize(img[:num_channels], img_size[1:])\n",
    "\n",
    "    return transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "64O4eKQXLqEr"
   },
   "outputs": [],
   "source": [
    "# Define the image size in (C, H, W) format\n",
    "img_size = (3, 150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8q6BXHmjQS2X"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\n",
    "    \"train\": nn.Sequential(\n",
    "        resize_remove(img_size),\n",
    "    ),\n",
    "    \"val\": nn.Sequential(\n",
    "        resize_remove(img_size),\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "USqNFV8v3HFM"
   },
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    phase: PetsDataset(\n",
    "        data[phase], img_dir=dataset_dir / \"images\", transform=data_transforms[phase]\n",
    "    )\n",
    "    for phase in [\"train\", \"val\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vp217ZXUdU2R"
   },
   "outputs": [],
   "source": [
    "dataset_size = {phase: len(datasets[phase]) for phase in [\"train\", \"val\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gEktVXxNOEc2"
   },
   "source": [
    "### Visualizing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wuuwdKUwYKwo"
   },
   "outputs": [],
   "source": [
    "def visualize_data(data, label_map, n_rows=3, n_cols=3):\n",
    "    \"\"\"Function to display n_rows * n_cols number of images of the passed `data`.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - data (Dataset or its subclass): Data which has to be visualized.\n",
    "    - label_map (dict): Mapping from int to labels for the classes.\n",
    "    - n_rows (int): Number of rows of images to display.\n",
    "    - n_cols (int): Number of columns of images to display.\n",
    "    \"\"\"\n",
    "    figure = plt.figure(figsize=(8, 8))\n",
    "    # Randomly choose the images to display from the data\n",
    "    idxs = torch.randint(high=len(data), size=(n_rows * n_cols,)).tolist()\n",
    "\n",
    "    for i, idx in enumerate(idxs):\n",
    "        img, label = data[idx]\n",
    "        figure.add_subplot(n_rows, n_cols, i + 1)\n",
    "        plt.title(label_map.get(label))\n",
    "        plt.axis(\"off\")\n",
    "        plt.imshow(img.permute((1, 2, 0)))  # change image to (H,W,C) format\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ayS1PSQid4eo"
   },
   "outputs": [],
   "source": [
    "species_map = {\n",
    "    0: \"Cat\",\n",
    "    1: \"Dog\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pKEpG7ceZMzF"
   },
   "outputs": [],
   "source": [
    "visualize_data(dataset[\"train\"], species_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUDHSNpmJ1GE"
   },
   "source": [
    "#### Create `DataLoader` objects for the training & validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZItRO-B27FwJ"
   },
   "outputs": [],
   "source": [
    "# define the batch size\n",
    "bs = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMzcEGxv7lF4"
   },
   "outputs": [],
   "source": [
    "dataloaders = {phase: DataLoader(datasets[phase], batch_size=bs, shuffle=True)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vLcvbTwl9dKn"
   },
   "source": [
    "<a name=\"training-a-deep-neural-network-for-binary-classification\"></a>\n",
    "\n",
    "---\n",
    "## Training a Deep Neural Network for Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBLf7veO_yZ5"
   },
   "source": [
    "In this section we will be training a simple `Feed-Forward Neural Network` on our pets dataset.<br> The output of the network will be one of the 2 classes, i.e. `Cat` or `Dog`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zAsbbr5Suvqr"
   },
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "\n",
    "from torch.optim.sgd import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dKtWmjCu944P"
   },
   "outputs": [],
   "source": [
    "class FeedForwardNetwork(nn.Module):\n",
    "    \"\"\"A class defining a simple Feedforward neural network\"\"\"\n",
    "\n",
    "    def __init__(self, img_size):\n",
    "        \"\"\"\n",
    "        Parameters:\n",
    "        -----------\n",
    "        - img_size: Dimensions of the input image.\n",
    "        \"\"\"\n",
    "        super(FeedForwardNetwork, self).__init__()\n",
    "        input_size = reduce(lambda x, y: x * y, img_size)\n",
    "\n",
    "        self.sequential = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.BatchNorm1d(input_size),\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Linear(64, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(16),\n",
    "            nn.Linear(16, 1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.sequential(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fXKNqY8dSj9S"
   },
   "outputs": [],
   "source": [
    "def train_val_model(\n",
    "    model,\n",
    "    dataloaders,\n",
    "    dataset_size,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    threshold=0.5,\n",
    "    device=\"cpu\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "    -----------\n",
    "    - dataloaders (dict-like): dict containing dataloader objects for the\n",
    "                               training & validation datasets.\n",
    "    - dataset_size (dict-like): dict containing the lengths for the training &\n",
    "                                validation datasets.\n",
    "    - model: The model which has to be trained (& used for making predictions).\n",
    "    - loss_fn (function): Loss function to use for calculating the gradients\n",
    "    - optimizer: Optimizer to use for updating the parameters of the model\n",
    "    - num_epochs (int): Number of epochs for which the model must be trained.\n",
    "    - theshold (float; default=0.5): Value above which the image will be\n",
    "                                     considered to belong to class `1`.\n",
    "    - device (str; default=\"cpu\"): Device to use for training the model.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    Dictionary containing the parameters of the model which had the best accuracy\n",
    "    on the validation set.\n",
    "    \"\"\"\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Initialize the best model weights as the initial weights of the model\n",
    "    best_model_parameters = copy.deepcopy(model.state_dict())\n",
    "    best_accuracy = 0.0\n",
    "\n",
    "    # Move the `model` to the specified `device`\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Initially set the gradients to zero\n",
    "    optimizer.grad_zero()\n",
    "\n",
    "    for i in range(num_epochs):\n",
    "        print(f\"Epoch {i}/{num_epochs-1}\")\n",
    "        print(\"-\" * 15)\n",
    "\n",
    "        # Both the training & validation datasets are passed to the model in\n",
    "        # each epoch\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            # Set mode depending upon the phase\n",
    "            if phase == \"train\":\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            total_loss = 0.0\n",
    "            total_corrects = 0\n",
    "\n",
    "            with torch.set_grad_enabled(phase == \"train\"):\n",
    "                for imgs, targets in dataloaders[\"phase\"]:\n",
    "                    imgs = imgs.to(device)\n",
    "                    targets = targets.to(device)\n",
    "                    predictions = model(imgs)\n",
    "                    loss = loss_fn(predictions, targets)\n",
    "                    total_loss += loss.item() * imgs.size(0)\n",
    "                    total_corrects += torch.sum(\n",
    "                        (predictions > threshold) == predictions\n",
    "                    )\n",
    "\n",
    "                    # Update parameter values during the training phase\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        # Set the gradients to zero\n",
    "                        optimizer.grad_zero()\n",
    "\n",
    "            avg_loss = total_loss / dataset_size[phase]\n",
    "            accuray = total_corrects / dataset_size[phase]\n",
    "            print(f\"{phase.capitalize()} Average Loss: {avg_loss: .4f}\")\n",
    "            print(f\"{phase.capitalize()} Accuracy: {accuracy: .4f}\")\n",
    "\n",
    "            if phase == \"val\" and accuracy < best_accuracy:\n",
    "                best_model_parameters = copy.deepcopy(model.state_dict())\n",
    "                best_accuracy = accuracy\n",
    "        # Print a new line after each epoch\n",
    "        print()\n",
    "\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Model training completed in {total_time//60}m {total_time % 60}s\")\n",
    "        print(f\"Minimum average validation loss: {min_val_loss}\")\n",
    "\n",
    "        return best_model_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebSHpLTZuvqu"
   },
   "source": [
    "### Create, train & validate model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A0sEIybwtQre"
   },
   "source": [
    "##### Use `GPU` for training if available else use `CPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3cwG_3Iztq58"
   },
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device being used: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BEv13zkFt7OB"
   },
   "outputs": [],
   "source": [
    "model = FeedForwardNetwork(img_size)\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "12Yinrb_OrWJ"
   },
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "lr = 1e-3\n",
    "optimizer = SGD(model.parameters(), lr)\n",
    "bce_loss = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kewGb2JbsOvr",
    "tags": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame(\n",
    "    [],\n",
    "    columns=[\"Training Loss\", \"Validation Loss\", \"Accuracy\"],\n",
    "    index=pd.Index([], name=\"Epoch No.\"),\n",
    ")\n",
    "for i in range(n_epochs):\n",
    "    train_loss = train_loop(train_dataloader, model, bce_loss, optimizer, device=device)\n",
    "    val_loss, accuracy = val_loop(val_dataloader, model, bce_loss, device=device)\n",
    "    results.loc[i] = [train_loss, val_loss, accuracy]\n",
    "    print(results.loc[i].to_frame().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qn4AYQ-VZb11"
   },
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2GtTSoRlxKYb"
   },
   "source": [
    "### Creating an Adversarial Example for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pdr6QGEU1Ek3"
   },
   "outputs": [],
   "source": [
    "x, y = val_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WfVnUw8-4Mne"
   },
   "outputs": [],
   "source": [
    "species_map.get(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IflxqhGU10IB"
   },
   "outputs": [],
   "source": [
    "x_new = x.detach().clone().float().unsqueeze(0).to(device).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mPJSIFeI2CtI"
   },
   "outputs": [],
   "source": [
    "y_new = 0 if y == 1 else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I7DIH57cMNZN"
   },
   "outputs": [],
   "source": [
    "y_new = torch.Tensor([[y_new]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Sj4mrx4H4_Sc"
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(x_new.permute((1, 2, 0)).type(torch.uint8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(species_map.get(y))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6zWsOiwg33OQ"
   },
   "outputs": [],
   "source": [
    "n_epochs = 40\n",
    "lr = 1e-1\n",
    "momentum = 0.9\n",
    "loss_func = nn.BCELoss()\n",
    "opt = SGD([x_new], lr, momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "StnnLD8p8lXn"
   },
   "outputs": [],
   "source": [
    "model(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hc-760tDL53Q"
   },
   "outputs": [],
   "source": [
    "for i in range(n_epochs):\n",
    "    pred = model(x_new)\n",
    "    opt.zero_grad()\n",
    "    loss = loss_func(pred, y_new)\n",
    "    loss.backward()\n",
    "    opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "emwTyD14EXj0"
   },
   "outputs": [],
   "source": [
    "model(x_new)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "5QVHLif75cnA"
   ],
   "name": "Adversarial_Attacks.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
